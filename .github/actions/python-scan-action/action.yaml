name: 'Python AI & Security Scan'
description: 'Scans Python code and AI models with Safe-Failure logic.'

inputs:
  github_token:
    description: 'GitHub token'
    required: true
    default: '${{ github.token }}'
  working-directory:
    description: 'Path to Python source code'
    required: false
    default: '.'
  fail_on_detection: # Consistent with your internal logic
    description: 'Fail workflow if critical issues are found'
    required: false
    default: 'true'

runs:
  using: "composite"
  steps:
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Security Tools
      shell: bash
      run: |
        pip install bandit pip-audit picklescan jq

    - name: ðŸ Run Bandit (Code SAST)
      id: bandit
      shell: bash
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "Running Bandit..."
        # Create empty report first to prevent jq crashes if bandit fails to start
        echo '{"results": []}' > bandit-report.json
        bandit -r . -lll -f json -o bandit-report.json || true

    - name: ðŸ“¦ Run Pip-Audit (Dependency SCA)
      id: audit
      shell: bash
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "Running Pip-Audit..."
        if [ -f "requirements.txt" ]; then
          pip-audit -r requirements.txt -f json -o audit-report.json || true
        else
          echo '{"dependencies": []}' > audit-report.json
        fi

    - name: ðŸ¥’ Run Picklescan (AI Supply Chain)
      id: picklescan
      shell: bash
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "Running Picklescan..."
        # Text output only - standard for current pip version
        touch picklescan-report.txt
        picklescan -p . > picklescan-report.txt 2>&1 || true

    - name: ðŸ“Š Generate Consolidated Report
      id: generate-report
      shell: bash
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "### ðŸ Python AI Security Report" >> $GITHUB_STEP_SUMMARY
        FOUND_ISSUES=false

        # 1. Bandit Results
        if [ -f bandit-report.json ]; then
          BANDIT_COUNT=$(jq '.results | length' bandit-report.json 2>/dev/null || echo "0")
          if [ "$BANDIT_COUNT" -gt 0 ]; then
            echo "#### ðŸ›¡ï¸ Bandit Code Issues ($BANDIT_COUNT)" >> $GITHUB_STEP_SUMMARY
            echo "| Severity | Issue | File:Line |" >> $GITHUB_STEP_SUMMARY
            echo "| :--- | :--- | :--- |" >> $GITHUB_STEP_SUMMARY
            jq -r '.results[] | "| \(.issue_severity) | \(.issue_text) | \(.filename):\(.line_number) |"' bandit-report.json >> $GITHUB_STEP_SUMMARY
            FOUND_ISSUES=true
          else
            echo "âœ… **Bandit:** Clean." >> $GITHUB_STEP_SUMMARY
          fi
        fi

        # 2. Picklescan Results
        if grep -q "dangerous" picklescan-report.txt; then
           echo "#### ðŸ¥’ ðŸ›‘ MALICIOUS MODEL DETECTED" >> $GITHUB_STEP_SUMMARY
           echo "Dangerous globals found in pickle files. **Critical supply chain risk.**" >> $GITHUB_STEP_SUMMARY
           echo '```text' >> $GITHUB_STEP_SUMMARY
           cat picklescan-report.txt >> $GITHUB_STEP_SUMMARY
           echo '```' >> $GITHUB_STEP_SUMMARY
           FOUND_ISSUES=true
        else
           echo "âœ… **Picklescan:** All models safe." >> $GITHUB_STEP_SUMMARY
        fi

        echo "issues_found=$FOUND_ISSUES" >> $GITHUB_OUTPUT

    - name: ðŸš¨ Report Python Security Incident
      if: steps.generate-report.outputs.issues_found == 'true'
      uses: Caladrius-Health-AI-Studio/github-actions/.github/actions/report-security-issue@main
      with:
        github_token: ${{ inputs.github_token }}
        scan_name: "Python AI & Code Security"
        severity: "CRITICAL"
        finding_summary: "Vulnerabilities detected in Bandit SAST or Picklescan."
        details_file_path: "bandit-report.json"
        remediation_steps: |
          1. **Picklescan:** Do not load flagged models. Convert to `safetensors`.
          2. **Bandit:** Review code for `exec()`, `eval()`, or hardcoded secrets.

    - name: Fail Workflow Gate
      if: steps.generate-report.outputs.issues_found == 'true' && inputs.fail_on_detection == 'true'
      shell: bash
      run: |
        echo "::error::Python Security Gate Failed. Check the summary for details."
        exit 1
