name: 'Python AI & Security Scan'
description: 'Scans Python code and AI models.'

inputs:
  github_token:
    description: 'GitHub token'
    required: true
    default: '${{ github.token }}'
  working-directory:
    description: 'Path to Python source code'
    required: false
    default: '.'
  fail_on_detection:
    description: 'Fail workflow if critical issues are found'
    required: false
    default: 'true'

runs:
  using: "composite"
  steps:
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Security Tools
      shell: bash
      run: |
        pip install bandit pip-audit picklescan jq

    - name: ðŸ Run Bandit (Code SAST)
      id: bandit
      shell: bash
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "Running Bandit..."
        # Bandit supports JSON natively
        bandit -r . -lll -f json -o bandit-report.json || true

    - name: ðŸ“¦ Run Pip-Audit (Dependency SCA)
      id: audit
      shell: bash
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "Running Pip-Audit..."
        if [ -f "requirements.txt" ]; then
          pip-audit -r requirements.txt -f json -o audit-report.json || true
        else
          echo "[]" > audit-report.json
        fi

    - name: ðŸ¥’ Run Picklescan (AI Supply Chain)
      id: picklescan
      shell: bash
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "Running Picklescan..."
        # FIX: Picklescan CLI does not output JSON. We save text output and grep it.
        picklescan -p . > picklescan-report.txt 2>&1 || true

    - name: ðŸ“Š Generate Consolidated Report
      id: generate-report  # <--- FIX: ADDED THIS ID SO THE NEXT STEP WORKS
      shell: bash
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "### ðŸ Python AI Security Report" >> $GITHUB_STEP_SUMMARY
        FOUND_ISSUES=false

        # --- 1. BANDIT REPORT ---
        BANDIT_COUNT=$(jq '.results | length' bandit-report.json 2>/dev/null || echo "0")
        if [ "$BANDIT_COUNT" -gt 0 ]; then
          echo "#### ðŸ›¡ï¸ Bandit Code Issues ($BANDIT_COUNT)" >> $GITHUB_STEP_SUMMARY
          jq -r '.results[] | "| \(.issue_severity) | \(.issue_text) | \(.filename):\(.line_number) |"' bandit-report.json >> $GITHUB_STEP_SUMMARY
          FOUND_ISSUES=true
        else
          echo "âœ… **Bandit:** Clean." >> $GITHUB_STEP_SUMMARY
        fi

        # --- 2. PICKLESCAN REPORT ---
        # FIX: Grep the text file for "dangerous" since JSON isn't available
        if grep -q "dangerous" picklescan-report.txt; then
           echo "#### ðŸ¥’ ðŸ›‘ MALICIOUS MODEL DETECTED" >> $GITHUB_STEP_SUMMARY
           echo "Dangerous globals found in pickle files. Check logs immediately." >> $GITHUB_STEP_SUMMARY
           cat picklescan-report.txt >> $GITHUB_STEP_SUMMARY
           FOUND_ISSUES=true
        else
           echo "âœ… **Picklescan:** No dangerous globals found." >> $GITHUB_STEP_SUMMARY
        fi

        echo "issues_found=$FOUND_ISSUES" >> $GITHUB_OUTPUT

    - name: Fail Workflow
      # FIX: Ensure logic checks outputs correctly
      if: steps.generate-report.outputs.issues_found == 'true' && inputs.fail_on_detection == 'true'
      shell: bash
      run: exit 1

    - name: ðŸš¨ Report Python Security Vulnerabilities
      if: steps.generate-report.outputs.issues_found == 'true'
      uses: Caladrius-Health-AI-Studio/github-actions/.github/actions/report-security-issue@main
      with:
        scan_name: "Python AI & Code Security"
        severity: "CRITICAL"
        finding_summary: "Vulnerabilities detected in Bandit SAST or Picklescan."
        details_file_path: "bandit-report.json"
        remediation_steps: |
          1. **Picklescan:** Dangerous models detected. Do not deploy.
          2. **Bandit:** Review the SAST report for hardcoded secrets/exec calls.
